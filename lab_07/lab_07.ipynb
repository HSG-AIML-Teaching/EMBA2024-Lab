{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j8IzyIVfRMO"
      },
      "source": [
        "# Working with Publically Available Pre-Trained Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pYvTx7heSdw"
      },
      "source": [
        "Within this notebook we will focus on the use of publically available pre-trained models.\n",
        "\n",
        "More specifically we will use the the **Diffusors Library** and **Transformers Library** by [Hugging Face](https://huggingface.co/). These libraries consist of thousands of pre-trained models many of which are trained on huge datasets for thousands of GPU hours. You can use them either directly for inference (as we will do in this lab session) or fine-tune them for your specific applications.\n",
        "\n",
        "**Pre-trained models versus building models from scratch:** Using pre-trained models allows you to reduce your compute costs and carbon footprint and save time and resources required to develop a model from scratch.\n",
        "\n",
        "**Pre-trained models versus APIs:** Compared to APIs these libraries are a bit more difficult to use, while they provide you with more control.\n",
        "\n",
        "The notebook also shows that libraries and APIs can be used flexibly combined and used hand in hand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LWZ2pzh2cgI"
      },
      "source": [
        "# Working with Stable Difussion for Image Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLeUGVM94zii"
      },
      "source": [
        "This section shows how to use Stable Diffussion  with the 🤗 Hugging Face [🧨 Diffusers library](https://github.com/huggingface/diffusers). The library can be used to create images from textual prompts with just a few lines of code.\n",
        "\n",
        "This section of the notebook has been adapted from [here](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qKyOIcE24Ap"
      },
      "source": [
        "### Seting Up the Stable Diffusion Pipeline\n",
        "\n",
        "Make sure you are using a GPU runtime to run this notebook, so inference is much faster. If the following command fails, use the `Runtime` menu above and select `Change runtime type`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "940tIRDq23BY"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "#Note that you need to replace cuda with cpu should you not get a GPU allocated"
      ],
      "metadata": {
        "id": "bVLR-5Fjqvqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opu4n0xp6PRj"
      },
      "source": [
        "Next, you should install `diffusers` as well `scipy`, `ftfy` and `transformers`. `accelerate` is used to achieve much faster loading.\n",
        "\n",
        "Moreover, we install with `transformers[sentencepiece] `, `openai` and `google-cloud-vision` some additionally packages which we need in later parts of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IX9pB0NU3c9C",
        "outputId": "d20c5cd1-232d-48da-de32-1a5572237724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/diffusers.git\n",
            "  Cloning https://github.com/huggingface/diffusers.git to /tmp/pip-req-build-r53okm3z\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /tmp/pip-req-build-r53okm3z\n",
            "  Resolved https://github.com/huggingface/diffusers.git to commit 5e96333cb2637fd5fb1fe76b00946555b491fb6d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.37.0-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.9.0-py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-cloud-vision\n",
            "  Downloading google_cloud_vision-3.5.0-py2.py3-none-any.whl (442 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.0.dev0) (7.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.0.dev0) (0.20.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.0.dev0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.0.dev0) (0.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.0.dev0) (9.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision) (2.11.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision) (1.23.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.62.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (2.17.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.60.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.48.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.26.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.26.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.26.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.26.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (4.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (0.5.1)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.26.0.dev0-py3-none-any.whl size=1867936 sha256=fab41979f4ab4c037d2646506ab10505b31846dac2e2702e7643d570afad950c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-aj947txf/wheels/4d/b7/a8/6f9549ceec5daad78675b857ac57d697c387062506520a7b50\n",
            "Successfully built diffusers\n",
            "Installing collected packages: sentencepiece, typing-extensions, scipy, h11, ftfy, httpcore, httpx, diffusers, accelerate, transformers, openai, google-cloud-vision\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.26.1 diffusers-0.26.0.dev0 ftfy-6.1.3 google-cloud-vision-3.5.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.9.0 scipy-1.12.0 sentencepiece-0.1.99 transformers-4.37.0 typing-extensions-4.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade git+https://github.com/huggingface/diffusers.git transformers transformers[sentencepiece] scipy ftfy accelerate openai google-cloud-vision\n",
        "#Note that this step can take a while"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgKS8xLG6gG5"
      },
      "source": [
        "`StableDiffusionPipeline` is an end-to-end inference pipeline that you can use to generate images from text with just a few lines of code. To use the `StableDiffusionPipeline` we have to first import it along with `torch`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6gHMd9oU00V"
      },
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW8MyDa1hS6x"
      },
      "source": [
        "Next, we load the pre-trained weights of all components of the model. In this notebook we use Stable Diffusion version 1.4 ([CompVis/stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4)), but there are other variants that you may want to try:\n",
        "* [runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)\n",
        "* [stabilityai/stable-diffusion-2-1-base](https://huggingface.co/stabilityai/stable-diffusion-2-1-base)\n",
        "* [stabilityai/stable-diffusion-2-1](https://huggingface.co/stabilityai/stable-diffusion-2-1). This version can produce images with a resolution of 768x768, while the others work at 512x512.\n",
        "\n",
        "In addition to the model id (i.e., [CompVis/stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4)), we pass `torch_dtype` to the `from_pretrained` method.\n",
        "\n",
        "To ensure that every free Google Colab can run Stable Diffusion, we load the weights from the half-precision branch [`fp16`](https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/fp16) and also tell `diffusers` to expect the weights in float16 precision by passing `torch_dtype=torch.float16`.\n",
        "\n",
        "If you want to ensure the highest possible precision, remove `torch_dtype=torch.float16` at the cost of a higher memory usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNsq_wWc3m__"
      },
      "outputs": [],
      "source": [
        "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "\n",
        "#Note that you need to replace float16 with float32 should you not get a GPU allocated and device=\"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H29j1DJ062qG"
      },
      "source": [
        "Next, we move the pipeline to GPU (device=\"cuda\") to have faster inference.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7doeSp803rep"
      },
      "outputs": [],
      "source": [
        "pipe = pipe.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjRIgNC47A84"
      },
      "source": [
        "## Generating Images with Stable Diffusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MtaUwjfpb4H"
      },
      "source": [
        "### Image Generation with Stable Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUXHGslIWV8m"
      },
      "outputs": [],
      "source": [
        "# function to generate image in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
        "def generate_image(prompt):\n",
        "  image = pipe(prompt).images[0]\n",
        "  image.save(\"astronaut_rides_horse.png\")\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEGll8S5Wcou"
      },
      "outputs": [],
      "source": [
        "prompt = \"a photograph of an astronaut riding a horse\"\n",
        "\n",
        "image = generate_image(prompt)\n",
        "\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIT73--r7Esv"
      },
      "source": [
        "Running the above cell multiple times will give you a different image every time. For **reproducibiltiy** use a `Generator` and set a manual seed. Every time you use the same seed you will have the same image result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMGAQPTO31bK"
      },
      "outputs": [],
      "source": [
        "generator = torch.Generator(device).manual_seed(1024)\n",
        "\n",
        "image = pipe(prompt, generator=generator).images[0]\n",
        "\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifqDbG0ph3JX"
      },
      "source": [
        "Getting the `DiffusionPipeline` to generate images in a certain style or include what you want can be tricky. Typically, it is necessary to run the `DiffusionPipeline` several times before ending up with an image you are satisfied with. Thus, it is important to reduce the time between inference cycles so you can iterate faster by getting the best speed and memory efficiency from the pipeline.\n",
        "\n",
        "For some tipps and tricks on effective and efficient Stable Difussion visit [here](https://huggingface.co/docs/diffusers/stable_diffusion)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjdUeMCWn0OY"
      },
      "source": [
        "### Efficient Image Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfxAHv-tVUq9"
      },
      "source": [
        "By default, the DiffusionPipeline runs inference with full `float32` precision for 50 inference steps. We already switched to a lower precision like `float16`.\n",
        "\n",
        "Another option for speed up is to reduce the number of inference steps using the `num_inference_steps` argument. In general, results are better the more steps you use.\n",
        "\n",
        "However, choosing a more efficient scheduler could help decrease the number of steps without sacrificing output quality.\n",
        "\n",
        "The Stable Diffusion model uses the `PNDMScheduler` by default which usually requires ~50 inference steps. However, there are more performant schedulers (e.g.,  `EulerDiscreteScheduler` which can do with less inference steps). You might need to experiment a bit to find the optimal range of steps for the different schedulers (for more details see [here](https://www.youtube.com/watch?v=N5ZAMa3BUxc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViopIa0Lnni1"
      },
      "source": [
        "To get the list of schedulers compatible with the used model use `pipe.scheduler.compatibles`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wluL0xZPnbyl"
      },
      "outputs": [],
      "source": [
        "pipe.scheduler.compatibles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLIYQdS9oh0F"
      },
      "source": [
        "\n",
        "To swap out the noise scheduler, pass it to `from_pre-trained`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX3-E_3qUvVO"
      },
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "\n",
        "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
        "\n",
        "#Use the Euler scheduler here instead\n",
        "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leetzSiIxcLL"
      },
      "outputs": [],
      "source": [
        "generator = torch.Generator(device).manual_seed(1024)\n",
        "image = pipe(prompt, num_inference_steps=30, generator=generator).images[0]\n",
        "display (image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbw4mXM_us-B"
      },
      "source": [
        "To generate multiple images for for the same prompt with a different number of steps, we simply call the pipeline multiple times with different step sizes and store the resulting images in a list.\n",
        "\n",
        "To show the generated images in a grid we use a helper function called `image_grid` which creates a grid of images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTZTorI4uxVQ"
      },
      "outputs": [],
      "source": [
        "#Helper function to create a grid of images\n",
        "from PIL import Image\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0y2sAnHorLp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "#Initially empt list images\n",
        "images = []\n",
        "\n",
        "#This loop creates images using 10 to 60 steps; the created images are added to list images\n",
        "for steps in range(10,61,10):\n",
        "  generator = torch.Generator(device).manual_seed(1024)\n",
        "  image = pipe(prompt, num_inference_steps=steps, generator=generator).images[0]\n",
        "  images.append(image)\n",
        "\n",
        "#displays the created list of images as grid\n",
        "image_grid(images, 2, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_trOxS1FjcW6"
      },
      "source": [
        "## Comparing Stable Difussion and OpenAI Images API"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next part of the notebook we compare Stable Diffussion with OpenAI's Images API."
      ],
      "metadata": {
        "id": "kBYP0q0MTUlq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh0_Hg5ZkYzz"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Protocol\n",
        "import os\n",
        "from pathlib import Path\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = 'COPY THE API_KEY HERE'\n",
        "\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkN77dXUjbbM"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LTrwqizj15D"
      },
      "outputs": [],
      "source": [
        "# function to generate image using OpenAI Images API\n",
        "def generate_OpenAI_image(prompt):\n",
        "  response = client.images.generate(\n",
        "    model=\"dall-e-3\",\n",
        "    prompt=prompt,\n",
        "    size=\"1024x1024\",\n",
        "    quality=\"standard\",\n",
        "    n=1,\n",
        "  )\n",
        "\n",
        "  return response.data[0].url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "su3ZUG4_2g8z"
      },
      "outputs": [],
      "source": [
        "# function to generate image in [PIL format](https://pillow.readthedocs.io/en/stable/) using Stable Diffusion\n",
        "def generate_SD_image(prompt):\n",
        "  generator=torch.Generator(device).manual_seed(1024)\n",
        "  image = pipe(prompt, num_inference_steps=30, generator=generator).images[0]\n",
        "  return image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIOPb9NykEPw"
      },
      "outputs": [],
      "source": [
        "prompt = \"a photograph of an astronaut riding a horse\"\n",
        "imageSD = generate_SD_image(prompt)\n",
        "imageOpenAI_URL = generate_OpenAI_image(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGNhFsrt1Ge2"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import urllib.request\n",
        "\n",
        "# To show the generated images in a grid we add them to initially empty list images\n",
        "images = []\n",
        "\n",
        "# Add image generated via Stable Diffusion\n",
        "images.append(imageSD)\n",
        "\n",
        "# Add image generated via OpenAI\n",
        "with urllib.request.urlopen(imageOpenAI_URL) as url:\n",
        "    img=Image.open(url)\n",
        "    smaller_img = img.resize((768, 768))\n",
        "    images.append(smaller_img)\n",
        "\n",
        "# Show all images from images[] in a grid\n",
        "image_grid(images, 1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3pejVTemBVc"
      },
      "source": [
        "To learn more about Stable Diffusion versus OpenAI Images API visit [here](https://zapier.com/blog/stable-diffusion-vs-dalle/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOOMgtAuDi4Y"
      },
      "source": [
        "# Working with the Transformers Library for Different Natural Language Processing Tasks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqLMXQQ03WIM"
      },
      "source": [
        "In this section of the notebook we will use the **Transformers Library** by [Hugging Face](https://huggingface.co/). The library consists of thousands of pre-trained models many of which are trained on huge datasets for thousands of GPU hours. You can use them either directly for inference (as we will do in this lab session) or fine-tune them for your specific applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOTJNeSN5_fK"
      },
      "source": [
        "The HuggingFace [ModelHub](https://huggingface.co/models) consists of various pre-trained models for different tasks which can be downloaded and used easily using the Transformers Library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL2GbiyXLbYL"
      },
      "source": [
        "##  Transformers for Translation Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYieC5X47Gfl"
      },
      "source": [
        "The easiest way to use a pre-trained model for inference is the **pipeline**. The pipeline can be used out-of-the box for many tasks across modalities (e.g., text, images, etc.). In this lab session we will look into a subset including translation and text classification.\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Task</th>\n",
        "    <th>Description</th>\n",
        "    <th>Pipeline identifier</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Translation</td>\n",
        "    <td>translate text from one language into another</td>\n",
        "    <td>pipeline(task=“translation”)</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Text classification</td>\n",
        "    <td>assign a label to a given sequence of text</td>\n",
        "    <td>pipeline(task=“sentiment-analysis”)</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Text generation</td>\n",
        "    <td>generate text that follows a given prompt</td>\n",
        "    <td>pipeline(task=“text-generation”)</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Image Classification</td>\n",
        "    <td>assign a label to an image</td>\n",
        "    <td>pipeline(task=“image-classification”)</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "For a comprehensive overview you can click [here](https://huggingface.co/docs/transformers/main/en/quicktour#pipeline).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7P3zBzF_XjI"
      },
      "source": [
        "As a first example we will explore the pipeline for translating text from one language to another one (use `pipeline(\"translation_xx_to_yy\")`) For example, to translate from English to German you can use `pipeline(\"translation_en_to_de\")`.\n",
        "\n",
        "The pipeline downloads and caches a default pre-trained model. You can then use it on your target text, e.g., `translated_text = translator(input_text)`.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYK429avs9qV"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "translator = pipeline(\"translation_en_to_de\")\n",
        "\n",
        "input_text = \"Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. \"\n",
        "translated_text = translator(input_text)\n",
        "print(translated_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3JR2dZjBIDG"
      },
      "source": [
        "Rather than using a default model, we will now use a **specific model** for the translation task and pass the model, which should be used for the translation to the pipeline as parameter.\n",
        "\n",
        "Just for translation tasks, more than 2800 pre-trained models can be found in the ModelHub which can be used together with the Transformers library (for an overview visit [here](https://huggingface.co/models?pipeline_tag=translation&library=transformers&sort=trending)).\n",
        "\n",
        "We will use `mdl_name = \"Helsinki-NLP/opus-mt-en-de\"`. You can find details concerning the model on its [model card](https://huggingface.co/Helsinki-NLP/opus-mt-en-de) in the ModelHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ptw8YMDKA6ng"
      },
      "outputs": [],
      "source": [
        "mdl_name = \"Helsinki-NLP/opus-mt-en-de\"\n",
        "translator = pipeline(\"translation\", model=mdl_name)\n",
        "\n",
        "input_text = \"Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. \"\n",
        "translated_text = translator(input_text)\n",
        "print(translated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm9NgQzBa_Oo"
      },
      "source": [
        "### Example: Combining Label Detection with Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLAmCgmwEVfW"
      },
      "source": [
        "We will now combine a translation task with the code for label detection via an existing API you already know from the previous session.\n",
        "\n",
        "More specifically, we will use Google Cloud Vision API for detecting a label in an image and then use the Transformers library for translating the detected text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NX4SS9xEIBV"
      },
      "outputs": [],
      "source": [
        "# Import the libraries\n",
        "from google.cloud import vision\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iOqpF5eEcse"
      },
      "outputs": [],
      "source": [
        "credentials = {\n",
        "##COPY the content of the JSON file here - remember you find it in Canvas##\n",
        "\n",
        "}\n",
        "\n",
        "json_credentials = json.dumps(credentials)\n",
        "\n",
        "with open('My Project-543e6ed386ee.json','w') as outfile:\n",
        "  outfile.write(json_credentials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWmsKiDDEfsy"
      },
      "outputs": [],
      "source": [
        "# Using the GOOGLE_APPLICATION_CREDENTIALS environment variable the location of a credential JSON file can be provided.\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'My Project-543e6ed386ee.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaIT2T9GEh9h"
      },
      "outputs": [],
      "source": [
        "# Instantiate the client (this only works with the credantials correctly set)\n",
        "client = vision.ImageAnnotatorClient()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV_SH4YRFEXA"
      },
      "outputs": [],
      "source": [
        "# Here we use a publicly-accessible URL as image URI\n",
        "# Before making the request we open the image via its uri and display it\n",
        "from PIL import Image\n",
        "import urllib.request\n",
        "\n",
        "uri = 'https://www.inside-digital.de/img/whatsapp-geburtstagssprueche2.jpg?class=1200x900'\n",
        "#uri = 'https://www.galaxus.ch/im/Files/2/8/7/1/1/2/6/5/959002-H-002.xxl3.jpgexportGa4PCo68TlLe9g?impolicy=ProductTileImage&resizeWidth=648&resizeHeight=486&cropWidth=648&cropHeight=486&resizeType=downsize&quality=high'\n",
        "\n",
        "with urllib.request.urlopen(uri) as url:\n",
        "    img=Image.open(url)\n",
        "    display(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqAWyMgNHnk7"
      },
      "outputs": [],
      "source": [
        "# Function to detect text in image\n",
        "def detectTextInImage(uri):\n",
        "\n",
        "  # Set image to be analyzed by Google Vision\n",
        "  image = vision.Image()\n",
        "  image.source.image_uri=uri\n",
        "\n",
        "  response_text = client.text_detection(image=image)\n",
        "\n",
        "  text=\"\"\n",
        "  # the if statement checks if text could be detected\n",
        "  if response_text.text_annotations:\n",
        "    text = response_text.text_annotations[0].description\n",
        "\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFmn8TboH-wc"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "#Translate output of label detection to english\n",
        "def translateText(prompt):\n",
        "  mdl_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
        "  translator = pipeline(\"translation\", model=mdl_name)\n",
        "  response = translator(prompt)\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSbY_KWlHi7v"
      },
      "outputs": [],
      "source": [
        "#Function to detect label in image and translate output of label detection\n",
        "def detect_and_translate_text(uri):\n",
        "\n",
        "  detectedText = detectTextInImage(uri)\n",
        "\n",
        "  print(detectedText)\n",
        "\n",
        "  response = translateText(detectedText)\n",
        "\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4J_2yaVF2Iy"
      },
      "outputs": [],
      "source": [
        "translatedText = detect_and_translate_text(uri)\n",
        "\n",
        "print(translatedText)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhj9DS8NL6X8"
      },
      "source": [
        "##  Transformers for Text Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0JThuAOE3Ki"
      },
      "source": [
        "In a next step we use the Transformers library for a text classification task (using `pipeline(\"sentiment-analysis\")`). As model we use a specific model (i.e.,\n",
        "`mdl_name = \"siebert/sentiment-roberta-large-english\"`), which is a fine-tuned checkpoint of a RoBERTa large model.\n",
        "\n",
        "Again visiting ModelHub you will find multiple models suitable for classification tasks. For an overview visit [here](https://huggingface.co/models?pipeline_tag=text-classification&library=transformers&sort=trending)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGC_QC51_dnH"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def classifyText(prompt):\n",
        "\n",
        "  mdl_name = \"siebert/sentiment-roberta-large-english\"\n",
        "  sentiment_pipeline = pipeline(\"sentiment-analysis\", model=mdl_name)\n",
        "\n",
        "  return sentiment_pipeline(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jy_Ak67SRUH"
      },
      "outputs": [],
      "source": [
        "prompt = \"I am super happy\"\n",
        "print(prompt + \": \" + str(classifyText(prompt)))\n",
        "\n",
        "prompt = \"The weather is awful today\"\n",
        "print(prompt + \": \" + str(classifyText(prompt)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWUYvQSdLGKP"
      },
      "source": [
        "This pipeline is very flexible. You can pass a list of prompts at a time and get multiple outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1iwu4ZKIdbo"
      },
      "outputs": [],
      "source": [
        "prompts = [\"I am super happy\", \"The weather is awful today\"]\n",
        "sentiments = classifyText(prompts)\n",
        "i = 0\n",
        "\n",
        "for prompt in prompts:\n",
        "  print (prompt + \": \" + str(sentiments[i]))\n",
        "  i = i + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp9owVGmTwg7"
      },
      "source": [
        "### Example: Sentiment Analysis of Twitter Data Using Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiC73xHfIHwy"
      },
      "source": [
        "This section is inspired by the following [Kaggle post](https://www.kaggle.com/code/kabirnagpal/vaccine-tweet-analysis-with-hugging-face)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiDOxVoz4pqa"
      },
      "source": [
        "#### Data Loading and Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset (https://www.kaggle.com/datasets/gpreda/all-covid19-vaccines-tweets)\n",
        "!wget https://raw.githubusercontent.com/HSG-AIML-Teaching/EMBA2024-Lab/main/lab_07/vaccination_tweets.csv"
      ],
      "metadata": {
        "id": "HbAX-K0p8bFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bde72ac-4e0f-4f4b-96c5-b4d5b047f4bc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-22 19:32:53--  https://raw.githubusercontent.com/HSG-AIML-Teaching/IEMBA2024-Lab/main/lab_07/vaccination_tweets.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4502265 (4.3M) [text/plain]\n",
            "Saving to: ‘vaccination_tweets.csv’\n",
            "\n",
            "vaccination_tweets. 100%[===================>]   4.29M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-01-22 19:32:54 (57.3 MB/s) - ‘vaccination_tweets.csv’ saved [4502265/4502265]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "WpKNMuZsUFmh"
      },
      "outputs": [],
      "source": [
        "# import required liabraries\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "W8563ZvHUXfa",
        "outputId": "aa00f32c-af8d-49c9-a1c0-b36a9b074355"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               user_location                 date  \\\n",
              "0  La Crescenta-Montrose, CA  2020-12-20 06:06:44   \n",
              "1          San Francisco, CA  2020-12-13 16:27:13   \n",
              "2                   Your Bed  2020-12-12 20:33:45   \n",
              "3     Vancouver, BC - Canada  2020-12-12 20:23:59   \n",
              "4                        NaN  2020-12-12 20:17:19   \n",
              "\n",
              "                                                text  \\\n",
              "0  Same folks said daikon paste could treat a cyt...   \n",
              "1  While the world has been on the wrong side of ...   \n",
              "2  #coronavirus #SputnikV #AstraZeneca #PfizerBio...   \n",
              "3  Facts are immutable, Senator, even when you're...   \n",
              "4  Explain to me again why we need a vaccine @Bor...   \n",
              "\n",
              "                                            hashtags               source  \\\n",
              "0                                 ['PfizerBioNTech']  Twitter for Android   \n",
              "1                                                NaN      Twitter Web App   \n",
              "2  ['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...  Twitter for Android   \n",
              "3                                                NaN      Twitter Web App   \n",
              "4     ['whereareallthesickpeople', 'PfizerBioNTech']   Twitter for iPhone   \n",
              "\n",
              "   retweets  is_retweet  \n",
              "0         0       False  \n",
              "1         1       False  \n",
              "2         0       False  \n",
              "3       446       False  \n",
              "4         0       False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cbc5ffe-8b8f-4990-a564-07e16a25ee7f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_location</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>source</th>\n",
              "      <th>retweets</th>\n",
              "      <th>is_retweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>La Crescenta-Montrose, CA</td>\n",
              "      <td>2020-12-20 06:06:44</td>\n",
              "      <td>Same folks said daikon paste could treat a cyt...</td>\n",
              "      <td>['PfizerBioNTech']</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>San Francisco, CA</td>\n",
              "      <td>2020-12-13 16:27:13</td>\n",
              "      <td>While the world has been on the wrong side of ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Your Bed</td>\n",
              "      <td>2020-12-12 20:33:45</td>\n",
              "      <td>#coronavirus #SputnikV #AstraZeneca #PfizerBio...</td>\n",
              "      <td>['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Vancouver, BC - Canada</td>\n",
              "      <td>2020-12-12 20:23:59</td>\n",
              "      <td>Facts are immutable, Senator, even when you're...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>446</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-12-12 20:17:19</td>\n",
              "      <td>Explain to me again why we need a vaccine @Bor...</td>\n",
              "      <td>['whereareallthesickpeople', 'PfizerBioNTech']</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cbc5ffe-8b8f-4990-a564-07e16a25ee7f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5cbc5ffe-8b8f-4990-a564-07e16a25ee7f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5cbc5ffe-8b8f-4990-a564-07e16a25ee7f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-de8da693-e2ce-4e2c-b789-f912f83766c8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de8da693-e2ce-4e2c-b789-f912f83766c8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-de8da693-e2ce-4e2c-b789-f912f83766c8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# read data into DataFrame\n",
        "df = pd.read_csv(\"vaccination_tweets.csv\").head(100)\n",
        "\n",
        "# drop columns which are not relevant\n",
        "df.drop([\"id\",\"user_name\", \"user_description\", \"user_created\", \"user_followers\", \"user_friends\", \"user_favourites\", \"user_verified\", \"favorites\"],axis=1,inplace=True)\n",
        "\n",
        "# print first 5 rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnHxYDjCmIDe"
      },
      "source": [
        "As we are focusing on tweets we'll extract the column \"text\". Let's print the first 5 tweets in the Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SythzoSsQspU"
      },
      "outputs": [],
      "source": [
        "tweets = df['text'].values\n",
        "tweets[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjfs9WoWmk2M"
      },
      "source": [
        "Before begining with our task let's first preprocess the data to remove URLs and Emojis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ3tf5LrQ5DJ"
      },
      "outputs": [],
      "source": [
        "def data_preprocess(words):\n",
        "\n",
        "    # removing any emojis or unknown charcters\n",
        "    words = words.encode('ascii','ignore')\n",
        "    words = words.decode()\n",
        "\n",
        "    # spliting string into words\n",
        "    words = words.split(' ')\n",
        "\n",
        "    # removing URLS\n",
        "    words = [word for word in words if not word.startswith('http')]\n",
        "    words = ' '.join(words)\n",
        "\n",
        "    # removing punctuations\n",
        "    words = re.sub(r\"[^0-9a-zA-Z]+\", \" \", words)\n",
        "\n",
        "   #  removing extra spaces\n",
        "    words = re.sub(' +', ' ', words)\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKDia4HRQ_Ml"
      },
      "outputs": [],
      "source": [
        "# We apply the preprocessing function to every tweet and display the first 5 tweets again\n",
        "tweets = [data_preprocess(tweet) for tweet in tweets]\n",
        "tweets[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_8FhNf1Q9e5"
      },
      "source": [
        "#### Using Pipelines for Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az1pGEe5nA21"
      },
      "source": [
        "Pipelines are a great and easy way to use models for inference. These pipelines are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks.\n",
        "\n",
        "The pipelines will download the pre-trained models one time and they can then be reused when ever required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dH2GTi6UG6h"
      },
      "outputs": [],
      "source": [
        "# create pipeline for sentiment analysis using the default model\n",
        "sentiment = pipeline('sentiment-analysis')\n",
        "\n",
        "# You can explore with alternative models to see which one works best for this particular context\n",
        "\n",
        "## Link to ModelCard: https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis\n",
        "# sentiment = pipeline('sentiment-analysis', \"finiteautomata/bertweet-base-sentiment-analysis\")\n",
        "\n",
        "## Link to ModelCard: https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment\n",
        "# !pip install emoji==0.6.0\n",
        "# sentiment = pipeline('sentiment-analysis', \"cardiffnlp/twitter-roberta-base-sentiment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KAzFnTvn7kn"
      },
      "source": [
        "Sentiment for tweet at index 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgle380tUl--"
      },
      "outputs": [],
      "source": [
        "print(tweets[1])\n",
        "print(sentiment(tweets[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgdDOa6SpDiV"
      },
      "source": [
        "Sentiment for tweet at index 4:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz3E0ykkpIvF"
      },
      "outputs": [],
      "source": [
        "print(tweets[4])\n",
        "print(sentiment(tweets[4]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ2pmP2So-BT"
      },
      "source": [
        "We can easily use the same API for batches of data as given below. This might take some time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8LGPXXARdrT"
      },
      "outputs": [],
      "source": [
        "sentiment(tweets[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBdLv1DVRvan"
      },
      "outputs": [],
      "source": [
        "# sentiments are stored in variable tweet_sentiment_data and put into a pandas DataFrame\n",
        "tweet_sentiment_data = sentiment(tweets)\n",
        "tweet_sentiment_data = pd.DataFrame(tweet_sentiment_data)\n",
        "# Here we create another DataFrame which shows the text of the tweet along the sentiment data\n",
        "tweetsWithSentiments = pd.concat([df[\"text\"], tweet_sentiment_data],axis=1,join=\"outer\")\n",
        "tweetsWithSentiments.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8zVB4HlRnpi"
      },
      "outputs": [],
      "source": [
        "# we count the different sentiments\n",
        "tweetsWithSentiments['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8L7Avp2qVf8"
      },
      "source": [
        "Hence we observe the dataset has more **Negative** tweets than **Positive**.\n",
        "\n",
        "As the API is traind on large and standardised data we can trust our predictions to a great extend. However, if you want to train for your own data you can fine-tune the model (see [here](https://medium.com/@lokaregns/fine-tuning-transformers-with-custom-dataset-classification-task-f261579ae068)).\n",
        "\n",
        "NOTE: The score here refers to te probability of the label."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a next step we create a histogram showing the distribution of labels."
      ],
      "metadata": {
        "id": "4SYR0wEe9nsl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1WhsY4drL24"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSx0IZlYq5QH"
      },
      "outputs": [],
      "source": [
        "px.histogram(tweetsWithSentiments, x=\"label\",nbins=100,opacity=.5,title=\"Tweets per Category\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1SPD7F742G0"
      },
      "source": [
        "#### Summarization of Tweets using Chat Completions API"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we combine the sentiment analysis with OpenAI's Chat Completions API to provide a summary of the tweets."
      ],
      "metadata": {
        "id": "t-0JQAw9Xo7o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgnhnMXavjVZ"
      },
      "outputs": [],
      "source": [
        "#Here we combine the first 25 tweets\n",
        "joinedTweets = ' '.join(tweets[:25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9N-DjMCwo5m"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yhi0y7W0v4zz"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = 'COPY THE API_KEY HERE'\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYPQJymNv5bI"
      },
      "outputs": [],
      "source": [
        "# Chat Completions API used for text summarization\n",
        "def summarizeTweets(joinedTweets):\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": \"Given a list of tweets, create a maximum 200 words summary .\"},\n",
        "      {\"role\": \"user\", \"content\": joinedTweets},\n",
        "    ]\n",
        "  )\n",
        "  return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDsJsvTMnV8-"
      },
      "outputs": [],
      "source": [
        "summarizeTweets(joinedTweets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZS_wDhjtfcn"
      },
      "source": [
        "#### Bonus: Generate Word Cloud from Tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51z3laGOVsvy"
      },
      "source": [
        "In this subsection we create a Word Cloud from Tweets using Python.\n",
        "\n",
        "This section is inspired by the following [Kaggle post](https://www.kaggle.com/code/jeongbinpark/pfizer-vaccine-tweets-analysis-with-wordcloud)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N84rim52VgfX"
      },
      "outputs": [],
      "source": [
        "# This piece of code takes the content of the twitter messages\n",
        "text_list = df[\"text\"].to_list()\n",
        "text = \"\"\n",
        "for i in text_list:\n",
        "    text = text + i.split(\"https:\")[0]\n",
        "\n",
        "text = text.replace(\" \",\",\")\n",
        "text = re.sub(\"[\\@\\#\\n\\.\\…\\?\\\\\\'\\d\\)\\(\\%\\*]\", \",\", text)\n",
        "text = re.sub(\",{2,}\", \",\", text)\n",
        "\n",
        "text[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7KwDIfZV_SH"
      },
      "outputs": [],
      "source": [
        "# Split into words\n",
        "text = text.split(',')\n",
        "text[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKT47BQwsC0-"
      },
      "outputs": [],
      "source": [
        "# Remove stop words\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def stop_w(x):\n",
        "    new_s = []\n",
        "    for i in text:\n",
        "        if i.lower() not in stopwords.words(\"english\"):\n",
        "            new_s.append(i.lower())\n",
        "    return new_s\n",
        "\n",
        "text = stop_w(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlH8U3B_TRRv"
      },
      "outputs": [],
      "source": [
        "# create word cloud\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_count = pd.Series(text).value_counts()\n",
        "wc = WordCloud(width=1000, height=600, background_color=\"white\", random_state=0)\n",
        "plt.figure(figsize=(20,10),facecolor='w')\n",
        "plt.imshow(wc.generate_from_frequencies(text_count))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}